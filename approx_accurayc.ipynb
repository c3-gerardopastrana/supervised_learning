{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc9b9ce-83cb-4097-af87-b439ce94b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "\n",
    "home = Path('/data')\n",
    "train_dir = home / 'datasets/imagenet_full_size/061417/train'\n",
    "test_dir = home / 'datasets/imagenet_full_size/061417/val'\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Apply transform_test for deterministic features\n",
    "trainset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "testset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Sample 10% of trainset\n",
    "subset_size = int(0.1 * len(trainset))\n",
    "indices = np.random.choice(len(trainset), subset_size, replace=False)\n",
    "train_subset = Subset(trainset, indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e85daf-364d-43ea-8bd2-9c2e9fe4bf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "import torch\n",
    "from train import ResNet18\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recreate model architecture\n",
    "n_classes = 1000  # or whatever your original number was\n",
    "lda_args = None   # or use the same lda_args you trained with\n",
    "\n",
    "checkpoint = torch.load(\"models/deeplda_best.pth\", map_location=device)\n",
    "\n",
    "# Rebuild model\n",
    "embedding_model = ResNet18(num_classes=n_classes, lda_args=lda_args)\n",
    "embedding_model.load_state_dict(checkpoint['state_dict'])\n",
    "embedding_model.to(device)\n",
    "embedding_model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cec810-12c5-424e-8626-73ae2dae21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 8.20%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Initialize the LDA model\n",
    "lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')  # Optional: you can tweak parameters\n",
    "\n",
    "# Fit the LDA model\n",
    "lda.fit(X_train.cpu().numpy(), y_train.cpu().numpy())\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lda.predict(X_test.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test.cpu().numpy(), y_pred)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef515d5d-2663-4698-b56c-37915ba8cc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def extract_embeddings(dataloader, model, device):\n",
    "    model.eval()\n",
    "    embeddings, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            feats = model._forward_features(x)  # Direct embeddings\n",
    "            feats = F.normalize(feats, p=2, dim=1)  # L2 normalization\n",
    "            embeddings.append(feats)\n",
    "            labels.append(y)\n",
    "    return torch.cat(embeddings), torch.cat(labels)\n",
    "\n",
    "X_train, y_train = extract_embeddings(train_loader, embedding_model, device)\n",
    "X_test, y_test = extract_embeddings(test_loader, embedding_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a2a90b-5c07-45a5-ac51-cfff63d0fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # --- Compute class centroids (normalized) ---\n",
    "# def compute_normalized_centroids_torch(X, y):\n",
    "#     classes = torch.unique(y)\n",
    "#     centroids = []\n",
    "#     for cls in classes:\n",
    "#         class_feats = X[y == cls]\n",
    "#         mean = class_feats.mean(dim=0, keepdim=True)\n",
    "#         mean = F.normalize(mean, p=2, dim=1)\n",
    "#         centroids.append(mean)\n",
    "#     return torch.cat(centroids, dim=0), classes\n",
    "\n",
    "# # --- Predict based on cosine similarity ---\n",
    "# def predict_cosine_torch(X, centroids, classes):\n",
    "#     X = F.normalize(X, p=2, dim=1)\n",
    "#     sims = torch.matmul(X, centroids.T)\n",
    "#     pred_indices = sims.argmax(dim=1)\n",
    "#     return classes[pred_indices]\n",
    "\n",
    "# # --- Main ---\n",
    "# # Make sure these are torch tensors on the right device\n",
    "# X_train_torch = X_train.to(device)\n",
    "# y_train_torch = y_train.to(device)\n",
    "# X_test_torch = X_test.to(device)\n",
    "# y_test_torch = y_test.to(device)\n",
    "\n",
    "# centroids, class_labels = compute_normalized_centroids_torch(X_train_torch, y_train_torch)\n",
    "# y_pred_torch = predict_cosine_torch(X_test_torch, centroids, class_labels)\n",
    "\n",
    "# # Convert to CPU and NumPy for scoring\n",
    "# acc = accuracy_score(y_test.cpu().numpy(), y_pred_torch.cpu().numpy())\n",
    "# print(f\"Centroid Cosine Classifier Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "model_state = embedding_model.state_dict()\n",
    "checkpoint_state = checkpoint['state_dict']\n",
    "\n",
    "model_keys = set(model_state.keys())\n",
    "checkpoint_keys = set(checkpoint_state.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for name in model_state:\n",
    "    if name in checkpoint_state:\n",
    "        if not torch.allclose(model_state[name], checkpoint_state[name], atol=1e-6):\n",
    "            print(f\"Value mismatch in {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9377e5d-7614-4851-9720-6d73c2bdbcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bff8db-249c-4a4b-bff2-97453fdd2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# --- Config ---\n",
    "batch_size = 4096\n",
    "lr = 1e-2\n",
    "epochs = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Prepare data ---\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "# --- Model, Loss, Optimizer ---\n",
    "model = LinearClassifier(X_train.shape[1], int(y_train.max().item()) + 1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training ---\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}: Train Accuracy = {acc:.2f}%\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb).argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "test_acc = correct / total * 100\n",
    "print(f\"Test Accuracy = {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868832fb-b1fa-4eac-9679-71b52c686c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
