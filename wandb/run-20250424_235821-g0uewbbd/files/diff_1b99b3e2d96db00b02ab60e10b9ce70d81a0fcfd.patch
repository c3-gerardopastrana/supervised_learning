diff --git a/lda.py b/lda.py
index cc368cf..f3bc930 100644
--- a/lda.py
+++ b/lda.py
@@ -1,7 +1,7 @@
 import torch
 import torch.nn as nn
 from functools import partial
-
+import torch.nn.functional as F
 
 def lda(X, y, n_classes, lamb):
     # flatten X
@@ -27,41 +27,119 @@ def lda(X, y, n_classes, lamb):
 
     # cope for numerical instability
     Sw += torch.eye(D, dtype=X.dtype, device=X.device, requires_grad=False) * lamb
+    #Sw = (1-lamb)*Sw + torch.eye(D, dtype=X.dtype, device=X.device, requires_grad=False) * lamb
+
+    # compute eigen decomposition
+    temp = torch.linalg.pinv(Sw, hermitian=True).matmul(Sb) #torch.linalg.solve(sigma_b, Sw ) 
+    # # evals, evecs = torch.symeig(temp, eigenvectors=True) # only works for symmetric matrix
+    # evals, evecs = torch.eig(temp, eigenvectors=True) # shipped from nightly-built version (1.8.0.dev20201015)
+    # print(evals.shape, evecs.shape)
+
+    # # remove complex eigen values and sort
+    # noncomplex_idx = evals[:, 1] == 0
+    # evals = evals[:, 0][noncomplex_idx] # take real part of eigen values
+    # evecs = evecs[:, noncomplex_idx]
+    # evals, inc_idx = torch.sort(evals) # sort by eigen values, in ascending order
+    # evecs = evecs[:, inc_idx]
+    # print(evals.shape, evecs.shape)
+
+    # # flag to indicate if to skip backpropagation
+    # hasComplexEVal = evecs.shape[1] < evecs.shape[0]
 
+    # return hasComplexEVal, Xc_mean, evals, evecs
     # compute eigen decomposition
-    temp = Sw.pinverse().matmul(Sb)
     # evals, evecs = torch.symeig(temp, eigenvectors=True) # only works for symmetric matrix
-    evals, evecs = torch.eig(temp, eigenvectors=True) # shipped from nightly-built version (1.8.0.dev20201015)
-    print(evals.shape, evecs.shape)
+    # Use the new torch.linalg.eig for general matrices
+    # It returns complex eigenvalues and eigenvectors by default
+    evals_complex, evecs_complex = torch.linalg.eig(temp)
 
-    # remove complex eigen values and sort
-    noncomplex_idx = evals[:, 1] == 0
-    evals = evals[:, 0][noncomplex_idx] # take real part of eigen values
-    evecs = evecs[:, noncomplex_idx]
-    evals, inc_idx = torch.sort(evals) # sort by eigen values, in ascending order
-    evecs = evecs[:, inc_idx]
-    print(evals.shape, evecs.shape)
+    # Process complex eigenvalues returned by torch.linalg.eig
+    # Check for eigenvalues with non-negligible imaginary parts
+    tol = 1e-6 # Tolerance for considering imaginary part zero
+    is_complex = torch.abs(evals_complex.imag) > tol
+    hasComplexEVal = torch.any(is_complex) # Flag if *any* eigenvalue was complex beyond tolerance
 
-    # flag to indicate if to skip backpropagation
-    hasComplexEVal = evecs.shape[1] < evecs.shape[0]
+    if hasComplexEVal:
+         # Optional: Print a warning if complex eigenvalues are detected
+         print(f"Warning: Found {torch.sum(is_complex)} eigenvalues with imaginary part > {tol}. Keeping only real eigenvalues.")
 
-    return hasComplexEVal, Xc_mean, evals, evecs
+    real_idx = ~is_complex
+    evals = evals_complex[real_idx].real 
+    evecs = evecs_complex[:, real_idx].real
+
+    if evals.numel() > 0: # Check if any real eigenvalues are left
+        evals, inc_idx = torch.sort(evals)
+        evecs = evecs[:, inc_idx]
+    else:
+        print("Warning: All eigenvalues were complex. Eigenvalue/vector tensors are empty.")
+        evals = torch.tensor([], dtype=temp.dtype, device=temp.device)
+        D = temp.shape[0]
+        evecs = torch.tensor([[] for _ in range(D)], dtype=temp.dtype, device=temp.device)
+    return hasComplexEVal, Xc_mean, evals, evecs, temp
 
 
 def lda_loss(evals, n_classes, n_eig=None, margin=None):
     n_components = n_classes - 1
     evals = evals[-n_components:]
     # evecs = evecs[:, -n_components:]
-    print('evals', evals.shape, evals)
+    # print('evals', evals.shape, evals)
     # print('evecs', evecs.shape)
 
     # calculate loss
     if margin is not None:
         threshold = torch.min(evals) + margin
         n_eig = torch.sum(evals < threshold)
-    loss = -torch.mean(evals[:n_eig]) # small eigen values are on left
+   
+    probs = evals / evals.sum()
+    entropy = -torch.sum(probs * torch.log(probs.clamp(min=1e-9)))
+
+    loss = -entropy
+    #loss = torch.mean(evals[:n_eig]) # small eigen values are on left
+    
+    # eigvals_norm = evals / evals.sum()
+    # eps = 1e-10 
+    # eigvals_norm = torch.clamp(eigvals_norm, min=eps)
+    # oss = (eigvals_norm * eigvals_norm.log()).sum()
+    #loss = torch.log(eigvals_norm.max()-eigvals_norm.min())
     return loss
+    
+def sina_loss(sigma_w_inv_b):
+    n = torch.tensor(2, dtype=sigma_w_inv_b.dtype, device=sigma_w_inv_b.device)
+
+    max_frobenius_norm = max_frobenius_norm = torch.trace(sigma_w_inv_b @ sigma_w_inv_b)
+    max_frobenius_norm = torch.sqrt(max_frobenius_norm.abs()) 
+    
+    trace = torch.trace(sigma_w_inv_b).abs()
+
+
 
+    lambda_target = torch.tensor(512, dtype=sigma_w_inv_b.dtype, device=sigma_w_inv_b.device)
+    
+
+    dim = sigma_w_inv_b.shape[0]
+    identity = torch.eye(dim, dtype=sigma_w_inv_b.dtype, device=sigma_w_inv_b.device)
+    diff = sigma_w_inv_b - lambda_target * identity
+    loss = torch.norm(diff, p='fro')**2
+    
+
+    
+    # penalty = (trace - lambda_target).pow(2) / lambda_target.pow(2)  # scale-free, minimal tuning
+    # loss = torch.log(max_frobenius_norm) -   torch.log(trace) + penalty
+    
+    # sigma_b_inv_w =  torch.linalg.pinv(sigma_w_inv_b, hermitian=True)
+    # min_frobenius_norm = torch.trace(sigma_b_inv_w @ sigma_b_inv_w)
+    # min_frobenius_norm = 1/torch.sqrt(min_frobenius_norm.abs())
+    
+    # gap =  max_frobenius_norm - min_frobenius_norm
+    #loss = torch.log(gap / trace)
+    
+    #trace = torch.trace(1/2*(sigma_w_inv_b + sigma_w_inv_b.T))
+    #loss = torch.log(max_frobenius_norm) - torch.log(trace)
+    
+    # off_diag = sigma_w_inv_b - torch.diag(torch.diagonal(sigma_w_inv_b))
+    # sum_squared_off_diag = torch.sum(off_diag ** 2).item()
+    # loss = sum_squared_off_diag - trace
+    return loss
 
 class LDA(nn.Module):
     def __init__(self, n_classes, lamb):
@@ -73,7 +151,7 @@ class LDA(nn.Module):
 
     def forward(self, X, y):
         # perform LDA
-        hasComplexEVal, Xc_mean, evals, evecs = self.lda_layer(X, y)  # CxD, D, DxD
+        hasComplexEVal, Xc_mean, evals, evecs, sigma_w_inv_b = self.lda_layer(X, y)  # CxD, D, DxD
 
         # compute LDA statistics
         self.scalings_ = evecs  # projection matrix, DxD
@@ -81,7 +159,7 @@ class LDA(nn.Module):
         self.intercept_ = -0.5 * torch.diagonal(Xc_mean.matmul(self.coef_.t())) # C
 
         # return self.transform(X)
-        return hasComplexEVal, evals
+        return hasComplexEVal, evals, sigma_w_inv_b
 
     def transform(self, X):
         """ transform data """
@@ -104,6 +182,161 @@ class LDA(nn.Module):
 
 
 
+def spherical_lda(X, y, n_classes, lamb):
+    N, D = X.shape
+    labels, counts = torch.unique(y, return_counts=True)
+    assert len(labels) == n_classes  # require all classes to be present
+    
+    # Compute global mean direction and normalize
+    global_mean = torch.mean(X, 0)
+    global_mean = F.normalize(global_mean, p=2, dim=0)
+    
+    # Initialize containers
+    class_means_list = []
+    Sw = torch.zeros((D, D), dtype=X.dtype, device=X.device)
+    Sb = torch.zeros((D, D), dtype=X.dtype, device=X.device)
+    
+    # Calculate all class means
+    for c in labels:
+        class_idx = int(c)
+        Xc = X[y == c]
+        class_mean = F.normalize(torch.mean(Xc, dim=0), p=2, dim=0)
+        class_means_list.append(class_mean)
+    
+    Xc_mean = torch.stack(class_means_list)
+    
+    # Compute scatter matrices
+    for i, (c, Nc) in enumerate(zip(labels, counts)):
+        Xc = X[y == c]
+        class_mean = Xc_mean[i]
+
+        # Vectorized cosine similarities
+        cos_similarities = Xc @ class_mean
+        cos_similarities = torch.clamp(cos_similarities, -1.0 + 1e-6, 1.0 - 1e-6)
+
+        # Vectorized difference: samples projected away from mean direction
+        diffs = Xc - cos_similarities.unsqueeze(1) * class_mean.unsqueeze(0)
+
+        # Vectorized scatter matrix
+        class_scatter = diffs.T @ diffs
+
+        Sw = Sw + class_scatter
+    
+    Sw = Sw / N  # Normalize by total number of samples
+    
+    # Compute between-class scatter
+    for i, (c, Nc) in enumerate(zip(labels, counts)):
+        class_mean = Xc_mean[i]
+        cos_sim = torch.dot(class_mean, global_mean)
+        cos_sim = torch.clamp(cos_sim, -1.0 + 1e-6, 1.0 - 1e-6)
+
+        diff = class_mean.unsqueeze(1) - cos_sim * global_mean.unsqueeze(1)
+        diff_outer = diff @ diff.T
+        Sb = Sb + (Nc / N) * diff_outer
+
+    
+    # import numpy as np
+    # from sklearn.covariance import LedoitWolf
+    
+    # X_np = Sw.cpu().detach().numpy()
+
+    # lw = LedoitWolf()
+    # lw.fit(X_np)
+    # shrinkage = lw.shrinkage_
+    # mu = torch.trace(Sw) / D
+    # shrinkage = torch.nn.Parameter(torch.tensor(0.0, dtype=Sw.dtype, device=Sw.device))
+    # shrinkage = torch.sigmoid(shrinkage)
+    
+    Sw_reg = Sw + torch.eye(D, dtype=X.dtype, device=X.device) * lamb
+    #Sw_reg = (1-shrinkage) * Sw + torch.eye(D, dtype=X.dtype, device=X.device, requires_grad=False) * shrinkage * mu
+    
+    
+    # Generalized eigenvalue problem
+    temp = torch.linalg.pinv(Sw_reg, hermitian=True) @ Sb
+    
+    # Eigen decomposition
+    evals_complex, evecs_complex = torch.linalg.eig(temp)
+    tol = 1e-6
+    is_complex = torch.abs(evals_complex.imag) > tol
+    hasComplexEVal = torch.any(is_complex)
+    
+    if hasComplexEVal:
+        print(f"Warning: Found {torch.sum(is_complex)} eigenvalues with imaginary part > {tol}. Keeping only real ones.")
+    
+    real_idx = ~is_complex
+    evals = evals_complex[real_idx].real
+    evecs = evecs_complex[:, real_idx].real
+    
+    if evals.numel() > 0:
+        evals, inc_idx = torch.sort(evals)
+        evecs = evecs[:, inc_idx]
+    else:
+        print("Warning: All eigenvalues were complex.")
+        evals = torch.tensor([], dtype=temp.dtype, device=temp.device)
+        evecs = torch.zeros((D, 0), dtype=temp.dtype, device=temp.device)
+    
+    return hasComplexEVal, Xc_mean, evals, evecs, temp
+
+
+class SphericalLDA(nn.Module):
+    def __init__(self, n_classes, lamb=1e-4):
+        super(SphericalLDA, self).__init__()
+        self.n_classes = n_classes
+        self.n_components = n_classes - 1  # Maximum meaningful LDA dimensions
+        self.lamb = lamb
+        self.lda_layer = partial(spherical_lda, n_classes=n_classes, lamb=lamb)
+    
+    def forward(self, X, y):
+        hasComplexEVal, Xc_mean, evals, evecs, sigma_w_inv_b = self.lda_layer(X, y)
+        
+        # Store projection matrix 
+        self.scalings_ = evecs
+        
+        # Project class means and normalize to create prototypes
+        projected_means = Xc_mean.matmul(evecs)
+        
+        # Project back to original space and normalize to ensure they're on the hypersphere
+        self.coef_ = F.normalize(projected_means.matmul(evecs.t()), p=2, dim=1)
+        
+        # Intercept is not meaningful in spherical space when using cosine similarity
+        self.intercept_ = torch.zeros(self.n_classes, dtype=X.dtype, device=X.device)
+        
+        return hasComplexEVal, evals, sigma_w_inv_b
+    
+    def transform(self, X):
+        # Normalize input
+        #X = F.normalize(X.view(X.shape[0], -1), p=2, dim=1)
+        
+        # Project data
+        X_new = X.matmul(self.scalings_)
+        
+        # Return only the most discriminative components
+        return X_new[:, :self.n_components]
+    
+    def predict(self, X):
+        # Normalize input embeddings
+        #X = F.normalize(X.view(X.shape[0], -1), p=2, dim=1)
+        
+        # Compute cosine similarities with class prototypes
+        similarities = X.matmul(self.coef_.t())
+        
+        # Return class with highest similarity
+        return torch.argmax(similarities, dim=1)
+    
+    def predict_proba(self, X):
+        #X = F.normalize(X.view(X.shape[0], -1), p=2, dim=1)
+        similarities = X.matmul(self.coef_.t())
+        
+        # Convert similarities to probabilities using softmax
+        proba = nn.functional.softmax(similarities, dim=1)
+        return proba
+    
+    def predict_log_proba(self, X):
+        #X = F.normalize(X.view(X.shape[0], -1), p=2, dim=1)
+        similarities = X.matmul(self.coef_.t())
+        log_proba = nn.functional.log_softmax(similarities, dim=1)
+        return log_proba
+
 if __name__ == '__main__':
     import numpy as np
     np.set_printoptions(precision=4, suppress=True)
diff --git a/train.py b/train.py
index 7520acb..06b62f1 100644
--- a/train.py
+++ b/train.py
@@ -11,10 +11,9 @@ from PIL import Image
 import torchvision
 import torchvision.transforms as transforms
 import torch.optim as optim
-
+import wandb
 from functools import partial
-from lda import LDA, lda_loss
-
+from lda import LDA, lda_loss, sina_loss, SphericalLDA
 
 class BasicBlock(nn.Module):
     expansion = 1
@@ -24,16 +23,16 @@ class BasicBlock(nn.Module):
         self.conv1 = nn.Conv2d(
             in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
         self.bn1 = nn.BatchNorm2d(planes)
-        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
-                               stride=1, padding=1, bias=False)
+        self.conv2 = nn.Conv2d(
+            planes, planes, kernel_size=3, stride=1, padding=1, bias=False)
         self.bn2 = nn.BatchNorm2d(planes)
 
         self.shortcut = nn.Sequential()
-        if stride != 1 or in_planes != self.expansion*planes:
+        if stride != 1 or in_planes != self.expansion * planes:
             self.shortcut = nn.Sequential(
-                nn.Conv2d(in_planes, self.expansion*planes,
+                nn.Conv2d(in_planes, self.expansion * planes,
                           kernel_size=1, stride=stride, bias=False),
-                nn.BatchNorm2d(self.expansion*planes)
+                nn.BatchNorm2d(self.expansion * planes)
             )
 
     def forward(self, x):
@@ -44,86 +43,64 @@ class BasicBlock(nn.Module):
         return out
 
 
-class Bottleneck(nn.Module):
-    expansion = 4
-
-    def __init__(self, in_planes, planes, stride=1):
-        super(Bottleneck, self).__init__()
-        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)
-        self.bn1 = nn.BatchNorm2d(planes)
-        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
-                               stride=stride, padding=1, bias=False)
-        self.bn2 = nn.BatchNorm2d(planes)
-        self.conv3 = nn.Conv2d(planes, self.expansion *
-                               planes, kernel_size=1, bias=False)
-        self.bn3 = nn.BatchNorm2d(self.expansion*planes)
-
-        self.shortcut = nn.Sequential()
-        if stride != 1 or in_planes != self.expansion*planes:
-            self.shortcut = nn.Sequential(
-                nn.Conv2d(in_planes, self.expansion*planes,
-                          kernel_size=1, stride=stride, bias=False),
-                nn.BatchNorm2d(self.expansion*planes)
-            )
-
-    def forward(self, x):
-        out = F.relu(self.bn1(self.conv1(x)))
-        out = F.relu(self.bn2(self.conv2(out)))
-        out = self.bn3(self.conv3(out))
-        out += self.shortcut(x)
-        out = F.relu(out)
-        return out
-
-
 class ResNet(nn.Module):
-    def __init__(self, block, num_blocks, n_classes, lda_args):
+    def __init__(self, block, num_blocks, num_classes=1000, lda_args=None):
         super(ResNet, self).__init__()
         self.lda_args = lda_args
-        if self.lda_args:  # LDA
-            self.in_planes = 32
-            self.out_planes = 16
-        else:  # Usual CNN with CE loss
-            self.in_planes = 32
-            self.out_planes = 16 # 64
-
-        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3,
-                               stride=1, padding=1, bias=False)
-        self.bn1 = nn.BatchNorm2d(self.in_planes)
-        self.layer1 = self._make_layer(block, self.out_planes*1, num_blocks[0], stride=1)
-        self.layer2 = self._make_layer(block, self.out_planes*2, num_blocks[1], stride=2)
-        self.layer3 = self._make_layer(block, self.out_planes*4, num_blocks[2], stride=2)
-        self.layer4 = self._make_layer(block, self.out_planes*8, num_blocks[3], stride=2)
+        self.in_planes = 64
+
+        # ImageNet-style initial conv layer
+        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,
+                               stride=2, padding=3, bias=False)
+        self.bn1 = nn.BatchNorm2d(64)
+        self.relu = nn.ReLU(inplace=True)
+        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
+
+        # Residual layers
+        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
+        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
+        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
+        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
+
+        # Global average pooling and output
+        self.avgpool = nn.AdaptiveAvgPool2d(1)
+        self.linear = nn.Linear(512 * block.expansion, num_classes)
+
+        # LDA branch (if enabled)
         if self.lda_args:
-            self.lda = LDA(n_classes, lda_args['lamb'])
-        else:
-            self.linear = nn.Linear(self.out_planes*8*block.expansion, n_classes)
+            self.lda = LDA(num_classes, lda_args['lamb'])  # your LDA class
 
     def _make_layer(self, block, planes, num_blocks, stride):
-        strides = [stride] + [1]*(num_blocks-1)
+        strides = [stride] + [1] * (num_blocks - 1)
         layers = []
         for stride in strides:
             layers.append(block(self.in_planes, planes, stride))
             self.in_planes = planes * block.expansion
         return nn.Sequential(*layers)
 
-    def forward(self, X, y):
-        out = F.relu(self.bn1(self.conv1(X)))
+    def forward(self, x, y=None, epoch=0):
+        out = self.relu(self.bn1(self.conv1(x)))
+        out = self.maxpool(out)
+
         out = self.layer1(out)
         out = self.layer2(out)
         out = self.layer3(out)
         out = self.layer4(out)
-        out = F.avg_pool2d(out, 4)
-        fea = out.view(out.size(0), -1)  # NxC
+
+        out = self.avgpool(out)  # output shape: [B, 512, 1, 1]
+        fea = out.view(out.size(0), -1)  # flatten to [B, 512]
+
         if self.lda_args:
-            hasComplexEVal, out = self.lda(fea, y)  # evals
-            return hasComplexEVal, fea, out
+            fea = F.normalize(fea, p=2, dim=1)
+            hasComplexEVal, out, sigma_w_inv_b = self.lda(fea, y)
+            return hasComplexEVal, fea, out, sigma_w_inv_b
         else:
             out = self.linear(fea)
             return out
 
 
-def ResNet18(n_classes, lda_args):
-    return ResNet(BasicBlock, [2, 2, 2, 2], n_classes, lda_args)
+def ResNet18(num_classes=1000, lda_args=None):
+    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes, lda_args)
 
 
 def ResNet34():
@@ -170,9 +147,12 @@ class Solver:
         if self.use_lda:
             self.criterion = partial(lda_loss, n_classes=n_classes, 
                                     n_eig=lda_args['n_eig'], margin=lda_args['margin'])
+            self.criterion = sina_loss
         else:
             self.criterion = nn.CrossEntropyLoss()
-        self.optimizer = optim.SGD(self.net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)
+        print(self.criterion)
+
+        self.optimizer = optim.AdamW(self.net.parameters(), lr=1e-3, weight_decay=5e-4)
         self.model_path = model_path
         self.n_classes = n_classes
 
@@ -182,39 +162,97 @@ class Solver:
         total_loss = 0
         correct = 0
         total = 0
+        entropy_sum = 0.0
+        entropy_count = 0
+        
         for batch_idx, (inputs, targets) in enumerate(dataloader):
             inputs = inputs.to(self.device)
             targets = targets.to(self.device)
             self.optimizer.zero_grad()
-            
+        
             if self.use_lda:
-                hasComplexEVal, feas, outputs = self.net(inputs, targets)
+                hasComplexEVal, feas, outputs, sigma_w_inv_b = self.net(inputs, targets, epoch)
                 if not hasComplexEVal:
-                    loss = self.criterion(outputs)
+
+                    #stats
+                    eigvals_norm = outputs / outputs.sum()
+                    eps = 1e-10 
+                    max_eigval_norm = eigvals_norm.max().item()
+                    min_eigval_norm = eigvals_norm.min().item()
+                    quantile_25 = torch.quantile(eigvals_norm, 0.25).item()
+                    quantile_50 = torch.quantile(eigvals_norm, 0.5).item()
+                    quantile_75 = torch.quantile(eigvals_norm, 0.75).item()
+                    eigvals_norm = torch.clamp(outputs / outputs.sum(), min=eps, max=1.0)
+                    eigvals_norm /= eigvals_norm.sum()
+                    entropy = -(eigvals_norm * eigvals_norm.log()).sum().item()
+                    entropy_sum += entropy
+                    entropy_count += 1
+                    trace = torch.trace(sigma_w_inv_b)
+                    rank_sigma = torch.linalg.matrix_rank(sigma_w_inv_b).item()
+                    condition_sigma = torch.linalg.cond(sigma_w_inv_b).item()     
+                    off_diag = sigma_w_inv_b - torch.diag(torch.diagonal(sigma_w_inv_b))
+                    sum_squared_off_diag = torch.sum(off_diag ** 2).item()
+                    diag_var = torch.var(torch.diagonal(sigma_w_inv_b)).item()
+    
+                    loss =  self.criterion(sigma_w_inv_b)
+
                     outputs = self.net.lda.predict_proba(feas)
+
+                    if phase == 'train':
+                        wandb.log({
+                            'loss': loss,
+                            
+                            "rank simga": rank_sigma,
+                            "condition simga": condition_sigma,
+                            "entropy": entropy,
+                            "sum_squared_off_diag": sum_squared_off_diag,
+                            "diag_var": diag_var,
+                            "trace": trace,
+                            "max normalized eigenvalue": max_eigval_norm,
+                            "min normalized eigenvalue": min_eigval_norm,
+                            "quantile_25": quantile_25,
+                            "quantile_50": quantile_50,
+                            "quantile_75": quantile_75})
+                    
                 else:
                     print('Complex Eigen values found, skip backpropagation of {}th batch'.format(batch_idx))
                     continue
             else:
-                outputs = self.net(inputs, targets)
-                loss = self.criterion(outputs, targets)            
-            # print('\noutputs shape:', outputs.shape)
-            # print('loss:', loss)
+                outputs = self.net(inputs, targets, epoch)
+                loss = nn.CrossEntropyLoss()(outputs, targets)
+        
             if phase == 'train':
+               
                 loss.backward()
+                grad_norm = torch.nn.utils.clip_grad_norm_(self.net.parameters(), max_norm=5.0)
                 self.optimizer.step()
+                wandb.log({"total_grad_norm_encoder":grad_norm.item()})
             total_loss += loss.item()
-
+    
             outputs = torch.argmax(outputs.detach(), dim=1)
-            # _, outputs = outputs.max(1)
             total += targets.size(0)
             correct += outputs.eq(targets).sum().item()
+        
         total_loss /= (batch_idx + 1)
-        total_acc = correct/total
+        if total > 0:
+            total_acc = correct / total
+        else:
+            total_acc = 0 
+        
+        if entropy_count > 0:
+            average_entropy = entropy_sum / entropy_count
+            print(f'Average Entropy: {average_entropy:.4f}')
+        
         print('\nepoch %d: %s loss: %.3f | acc: %.2f%% (%d/%d)'
                      % (epoch, phase, total_loss, 100.*total_acc, correct, total))
+        wandb.log({
+            "epoch"+phase:epoch,
+             "total"+phase:total_loss,
+             "total_acc_train"+phase: 100.*total_acc
+        }) 
         return total_loss, total_acc
 
+
     def train(self, epochs):
         best_loss = float('inf')
         for epoch in range(epochs):
@@ -238,10 +276,10 @@ class Solver:
                 inputs = inputs.to(self.device)
                 targets = targets.to(self.device)
                 if self.use_lda:
-                    _, feas, outputs = self.net(inputs, targets)
+                    _, feas, outputs = self.net(inputs, targets, epoch)
                     outputs = self.net.lda.predict_proba(feas)
                 else:
-                    outputs = self.net(inputs, targets)
+                    outputs = self.net(inputs, targets, epoch)
                 outputs = torch.argmax(outputs, dim=1)
                 y_pred.append(outputs.detach().cpu().numpy())
                 y_true.append(targets.detach().cpu().numpy())
@@ -279,56 +317,71 @@ def parse_dir(img_dir, classes, randnum=-1):
 
 
 if __name__ == '__main__':
+    import os
+    import wandb
+    import torch
+    from torchvision import transforms, datasets
+    from torch.utils.data import DataLoader, random_split
+
+    wandb.init(
+        project="DeepLDA",
+        entity="gerardo-pastrana-c3-ai",
+        group="gapLoss",
+    )
+
+    seed = 42
+    torch.manual_seed(seed)
+
+    n_classes = 1000
+    train_val_split = 0.1
+    batch_size = 128
+    num_workers = 8
+    gpu = 0
+
+    train_dir = 'datasets/imagenet_full_size/061417/train'
+    val_dir = 'datasets/imagenet_full_size/061417/val'
+    model_path = 'models/deeplda_best.pth'
+
+    # ImageNet normalization
+    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
+                                     std=[0.229, 0.224, 0.225])
+
     transform_train = transforms.Compose([
-        transforms.RandomCrop(32, padding=2),
+        transforms.RandomResizedCrop(224),
         transforms.RandomHorizontalFlip(),
+        transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET),
         transforms.ToTensor(),
-        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
+        normalize,
     ])
 
     transform_test = transforms.Compose([
+        transforms.Resize(256),
+        transforms.CenterCrop(224),
         transforms.ToTensor(),
-        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
+        normalize,
     ])
 
-    seed = 42
-    n_classes = 10
-    train_val_split = 0.2
-    batch_size = 5000
-    num_workers = 4
-    gpu = -1
+    # Create datasets
+    full_trainset = datasets.ImageFolder(train_dir, transform=transform_train)
+    N = len(full_trainset)
+    Ntrain, Nval = N - int(N * train_val_split), int(N * train_val_split)
+    trainset, valset = random_split(full_trainset, [Ntrain, Nval])
+
+    testset = datasets.ImageFolder(val_dir, transform=transform_test)
 
-    train_dir = '../data/cifar10/imgs/train'
-    test_dir = '../data/cifar10/imgs/test'
-    model_path = '../data/cifar10/exp1015/deeplda_best.pth'
+    # Dataloaders
+    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)
+    valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)
+    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)
 
-    loss = 'LDA' # CE or LDA
+    dataloaders = {'train': trainloader, 'val': valloader, 'test': testloader}
+
+    loss = 'LDA'
     lamb = 0.0001
     n_eig = 4
     margin = None
-    lda_args = {'lamb':lamb, 'n_eig':n_eig, 'margin':margin} if loss == 'LDA' else {}
+    lda_args = {'lamb': lamb, 'n_eig': n_eig, 'margin': margin} if loss == 'LDA' else {}
 
-    class_map = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 
-                 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}
-    
-    ids = parse_dir(train_dir, os.listdir(train_dir))
-    train_img_names = [os.path.join(train_dir, *f.split('+')) for f in ids]
-    trainset = CIFAR10(train_img_names, class_map, transform_train)
-    N = len(trainset)
-    Ntrain, Nval = N - int(N * train_val_split), int(N * train_val_split)
-    trainset, valset = torch.utils.data.random_split(trainset, [Ntrain, Nval])
-    trainloader = torch.utils.data.DataLoader(
-        trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
-    valloader = torch.utils.data.DataLoader(
-        valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
-
-    test_ids = parse_dir(test_dir, os.listdir(test_dir))
-    test_img_names = [os.path.join(test_dir, *f.split('+')) for f in test_ids]
-    testset = CIFAR10(test_img_names, class_map, transform_test)
-    testloader = torch.utils.data.DataLoader(
-        testset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
-
-    dataloaders = {'train':trainloader, 'val':valloader, 'test':testloader}
     solver = Solver(dataloaders, model_path, n_classes, lda_args, gpu)
-    solver.train(20)
+    solver.train(100)
     solver.test()
