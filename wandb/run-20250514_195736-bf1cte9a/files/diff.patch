diff --git a/lda.py b/lda.py
index 733c9a1..9270a93 100644
--- a/lda.py
+++ b/lda.py
@@ -90,7 +90,7 @@ def sina_loss(sigma_w_inv_b, sigma_w, sigma_b, xc_mean, sigma_t):
     mu = xc_mean.mean(dim=0)       # (D,)
     mean_term = torch.sum(mu ** 2)
     # loss = (torch.log(torch.trace(sigma_t)) - torch.log(torch.trace(sigma_b))) + mean_term
-    # n = torch.tensor(512, dtype=sigma_w_inv_b.dtype, device=sigma_w_inv_b.device)
+    n = torch.tensor(512, dtype=sigma_w_inv_b.dtype, device=sigma_w_inv_b.device)
 
     # max_frobenius_norm = torch.trace(sigma_w_inv_b @ sigma_w_inv_b)
     # max_frobenius_norm = torch.sqrt(max_frobenius_norm.abs()) 
@@ -99,8 +99,8 @@ def sina_loss(sigma_w_inv_b, sigma_w, sigma_b, xc_mean, sigma_t):
     # penalty = (trace - lambda_target).pow(2) / lambda_target
     # # penalty = 0.01 * (torch.log(torch.trace(sigma_w)) - torch.log(torch.trace(sigma_b)))
     # loss = torch.log(max_frobenius_norm) -  torch.log(trace) + penalty
-    loss = torch.log(torch.norm(sigma_t, p='fro')) - torch.log(torch.trace(sigma_t)) + mean_term
-    
+    loss = wasserstein_proxy_loss(xc_mean, sigma_w + sigma_b) # + torch.norm(sigma_w, p='fro') ** 2 / n
+    #triangle_loss(Xc_mean, Sb, Sw, epsilon = 0.15)
 
     
     
@@ -306,7 +306,61 @@ def spherical_lda(X, y, n_classes, lamb):
         evecs = torch.zeros((D, 0), dtype=temp.dtype, device=temp.device)
     
     return hasComplexEVal, Xc_mean, evals, evecs, temp
+    
+def triangle_loss(Xc_mean, Sb, Sw, epsilon = 0.15):
+    """
+    Wasserstein proxy loss:
+    Penalizes deviation of class means from 0 and total scatter matrix from (1/n) * I.
+
+    Args:
+        Xc_mean: (n_classes, D) tensor of class means
+        St: (D, D) total scatter matrix
+        n_classes: int, number of classes (used to scale identity)
 
+    Returns:
+        Scalar proxy Wasserstein^2 loss
+    """
+    D = Sw.shape[0]
+    device = Sw.device
+
+    # 1. Mean penalty: encourage mean of class means to be near 0
+    mu = Xc_mean.mean(dim=0)  # (D,)
+    mean_term = torch.sum(mu ** 2)
+
+    # 2. Frobenius norm penalty: encourage St ≈ (1/n) * I
+    target = (1.0 / D) * torch.eye(D, device=device)
+    frob_term_b = torch.norm(Sb - epsilon * target, p='fro') ** 2
+    frob_term_w = torch.norm(Sw - (1-epsilon) * target, p='fro') ** 2
+    
+
+    return mean_term + frob_term_b + frob_term_w
+    
+def wasserstein_proxy_loss(Xc_mean, St):
+    """
+    Wasserstein proxy loss:
+    Penalizes deviation of class means from 0 and total scatter matrix from (1/n) * I.
+
+    Args:
+        Xc_mean: (n_classes, D) tensor of class means
+        St: (D, D) total scatter matrix
+        n_classes: int, number of classes (used to scale identity)
+
+    Returns:
+        Scalar proxy Wasserstein^2 loss
+    """
+    D = St.shape[0]
+    device = St.device
+
+    # 1. Mean penalty: encourage mean of class means to be near 0
+    mu = Xc_mean.mean(dim=0)  # (D,)
+    mean_term = torch.sum(mu ** 2)
+
+    # 2. Frobenius norm penalty: encourage St ≈ (1/n) * I
+    target = (1.0 / D) * torch.eye(D, device=device)
+    frob_term = torch.norm(St - target, p='fro') ** 2
+
+    return mean_term + frob_term
+    
 def wasserstein_loss(Xc_mean, St):
     """
     Computes the squared 2-Wasserstein distance between 
diff --git a/train.py b/train.py
index e17b5cc..2a39500 100644
--- a/train.py
+++ b/train.py
@@ -221,7 +221,7 @@ class Solver:
 
 def setup(rank, world_size):
     os.environ['MASTER_ADDR'] = 'localhost'
-    os.environ['MASTER_PORT'] = '12354'
+    os.environ['MASTER_PORT'] = '12355'
     
     # Initialize the process group
     dist.init_process_group("nccl", rank=rank, world_size=world_size)
diff --git a/wandb/latest-run b/wandb/latest-run
index 724b935..5c893f7 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20250514_023337-no5goqf3
\ No newline at end of file
+run-20250514_195736-bf1cte9a
\ No newline at end of file
diff --git a/wandb/run-20250514_023337-no5goqf3/run-no5goqf3.wandb b/wandb/run-20250514_023337-no5goqf3/run-no5goqf3.wandb
index e54b50a..c4a98cd 100644
Binary files a/wandb/run-20250514_023337-no5goqf3/run-no5goqf3.wandb and b/wandb/run-20250514_023337-no5goqf3/run-no5goqf3.wandb differ
