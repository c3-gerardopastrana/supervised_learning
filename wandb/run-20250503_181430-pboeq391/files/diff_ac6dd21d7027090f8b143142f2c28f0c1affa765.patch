Submodule apex contains modified content
diff --git a/apex/setup.py b/apex/setup.py
index 4aa6616..3e369a7 100644
--- a/apex/setup.py
+++ b/apex/setup.py
@@ -37,15 +37,15 @@ def check_cuda_torch_binary_vs_bare_metal(cuda_dir):
     print("\nCompiling cuda extensions with")
     print(raw_output + "from " + cuda_dir + "/bin\n")
 
-    if (bare_metal_version != torch_binary_version):
-        raise RuntimeError(
-            "Cuda extensions are being compiled with a version of Cuda that does "
-            "not match the version used to compile Pytorch binaries.  "
-            "Pytorch binaries were compiled with Cuda {}.\n".format(torch.version.cuda)
-            + "In some cases, a minor-version mismatch will not cause later errors:  "
-            "https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  "
-            "You can try commenting out this check (at your own risk)."
-        )
+    # if (bare_metal_version != torch_binary_version):
+    #     raise RuntimeError(
+    #         "Cuda extensions are being compiled with a version of Cuda that does "
+    #         "not match the version used to compile Pytorch binaries.  "
+    #         "Pytorch binaries were compiled with Cuda {}.\n".format(torch.version.cuda)
+    #         + "In some cases, a minor-version mismatch will not cause later errors:  "
+    #         "https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  "
+    #         "You can try commenting out this check (at your own risk)."
+    #     )
 
 
 def raise_if_cuda_home_none(global_option: str) -> None:
diff --git a/train.py b/train.py
index 8e7ceec..6001aad 100644
--- a/train.py
+++ b/train.py
@@ -81,7 +81,7 @@ class Solver:
     
         if hasComplexEVal:
             print(f'Complex Eigenvalues found, skipping batch {batch_idx}')
-            return None, None, None
+            return None
     
         metrics = compute_wandb_metrics(outputs, sigma_w_inv_b)
         loss = self.criterion(sigma_w_inv_b)
@@ -494,12 +494,12 @@ if __name__ == '__main__':
         'test_dir': '/data/datasets/imagenet_full_size/061417/test',
         'model_path': 'models/deeplda_best.pth',
         'loss': 'LDA',
-        'lamb': 0.1,
+        'lamb': 0.001,
         'n_eig': 4,
         'margin': None,
         'epochs': 25,
-        'k_classes': 16,
-        'n_samples': 512,
+        'k_classes': 256,
+        'n_samples': 32,
         # Memory optimization parameters
         'gradient_accumulation_steps': 1,  # Accumulate gradients to save memory
         'use_amp': True,                   # Use automatic mixed precision
diff --git a/wandb/latest-run b/wandb/latest-run
index 348b0df..991a8a9 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20250501_223401-hduatagi
\ No newline at end of file
+run-20250503_181430-pboeq391
\ No newline at end of file
diff --git a/wandb/run-20250501_223401-hduatagi/run-hduatagi.wandb b/wandb/run-20250501_223401-hduatagi/run-hduatagi.wandb
index c515fad..b20b3cf 100644
Binary files a/wandb/run-20250501_223401-hduatagi/run-hduatagi.wandb and b/wandb/run-20250501_223401-hduatagi/run-hduatagi.wandb differ
